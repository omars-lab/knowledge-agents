services:
  # PostgreSQL Database
  postgres:
    image: postgres:15
    environment:
      POSTGRES_DB: knowledge_workflow
      POSTGRES_USER: knowledge
      POSTGRES_PASSWORD: knowledge123
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./data/01-init-db.sql:/docker-entrypoint-initdb.d/01-init-db.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U knowledge -d knowledge_workflow"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Prometheus Monitoring
  prometheus:
    image: prom/prometheus:latest
    platform: linux/arm64
    ports:
      - "9090:9090"
    volumes:
      - ./config/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./config/recording_rules.yml:/etc/prometheus/recording_rules.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    depends_on:
      - agentic-api

  # Qdrant Vector Database
  qdrant:
    image: qdrant/qdrant:latest
    ports:
      - "6333:6333"  # HTTP API
      - "6334:6334"  # gRPC API
    volumes:
      - qdrant_data:/qdrant/storage
    healthcheck:
      # https://github.com/qdrant/qdrant/issues/4250
      test: ["CMD", "bash", "-c", "exec 3<>/dev/tcp/127.0.0.1/6333 && echo -e 'GET /readyz HTTP/1.1\\r\\nHost: localhost\\r\\nConnection: close\\r\\n\\r\\n' >&3 && grep -q 'HTTP/1.1 200' <&3"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Tidy MCP Server - HTTP wrapper for MCP tools
  tidy-mcp:
    build:
      context: ../tidy-mcp
      dockerfile: Dockerfile
    environment:
      - PYTHONPATH=/app/src
    volumes:
      # Mount NotePlan directory for x-callback-url generation
      - "/Users/omareid/Library/Containers/co.noteplan.NotePlan3/Data/Library/Application Support/co.noteplan.NotePlan3/:/noteplan:ro"
    ports:
      - "8003:8000"  # HTTP API port
    command: ["python", "-m", "uvicorn", "tidy_mcp.http_server:app", "--host", "0.0.0.0", "--port", "8000"]
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Agentic API
  agentic-api:
    build:
      context: .
      dockerfile: Dockerfile
      target: app
    ports:
      - "8001:8000"      # Main service port
      - "8002:8002"      # Metrics port
    environment:
      - DATABASE_URL=postgresql://knowledge:knowledge123@postgres:5432/knowledge_workflow
      - API_HOST=0.0.0.0
      - API_PORT=8000
      - TIDY_MCP_URL=http://tidy-mcp:8000  # URL for tidy-mcp HTTP service
    secrets:
      - openai_api_key
    volumes:
      - ./build/logs:/app/build/logs
      - ./build/metrics:/app/build/metrics
    depends_on:
      postgres:
        condition: service_healthy
      qdrant:
        condition: service_healthy
      llm-proxy:
        condition: service_healthy
      tidy-mcp:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Canary Container - Continuous monitoring with random payloads
  # canary:
  #   build:
  #     context: .
  #     dockerfile: Dockerfile
  #     target: build
  #   environment:
  #     - DATABASE_URL=postgresql://knowledge:knowledge123@postgres:5432/knowledge_workflow
  #     - CANARY_INTERVAL=30  # Run canary every 30 seconds
  #     - CANARY_DEBUG=true  # Enable debug logging for canary
  #   volumes:
  #     - ./scripts:/app/scripts
  #     - ./build/logs:/app/build/logs
  #   command: ["python", "/app/scripts/canary_monitor.py"]
  #   depends_on:
  #     agentic-api:
  #       condition: service_healthy
  #   restart: unless-stopped
  #   healthcheck:
  #     test: ["CMD", "python", "-c", "import requests; requests.get('http://agentic-api:8000/health')"]
  #     interval: 60s
  #     timeout: 10s
  #     retries: 3

  # LiteLLM Proxy Server
  llm-proxy:
    build:
      context: .
      dockerfile: Dockerfile
      target: litellm-proxy
    ports:
      - "4000:4000"
    environment:
      - LM_STUDIO_HOST=${LM_STUDIO_HOST:-192.168.1.168}
      - LM_STUDIO_PORT=${LM_STUDIO_PORT:-1234}
      - LITELLM_PORT=4000
      - LITELLM_HOST=0.0.0.0
    secrets:
      - openai_api_key
      - admin_api_key
    volumes:
      - ./config/litellm_config.yaml:/app/config/litellm_config.yaml:ro
      - ./scripts/containers/litellm:/app/scripts:ro
    command: >
      sh -c "
        python3 /app/scripts/start_litellm_proxy.py
      "
    depends_on:
      postgres:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "/app/scripts/healthcheck_litellm.sh"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  # Test Service (uses build stage with test dependencies)
  test:
    build:
      context: .
      dockerfile: Dockerfile
      target: build
    environment:
      - DATABASE_URL=postgresql://knowledge:knowledge123@postgres:5432/knowledge_workflow
      - ENVIRONMENT=test
      - TIDY_MCP_URL=http://tidy-mcp:8000  # URL for tidy-mcp HTTP service
    secrets:
      - openai_api_key
    volumes:
      - ./build:/app/build
      - ./tst:/app/tst
      - ./src:/app/src
      - ./scripts/containers/test:/app/scripts/containers/test:ro
    depends_on:
      postgres:
        condition: service_healthy
      qdrant:
        condition: service_healthy
      llm-proxy:
        condition: service_healthy
      agentic-api:
        condition: service_healthy
      tidy-mcp:
        condition: service_healthy
    command: ["tail", "-f", "/dev/null"]  # Keep container running


  # Seeder Service - runs database and vector store seeding (one-time, no restart)
  seeder:
    build:
      context: .
      dockerfile: Dockerfile
      target: seeder
    environment:
      - DATABASE_URL=postgresql://knowledge:knowledge123@postgres:5432/knowledge_workflow
      - ENVIRONMENT=production
    secrets:
      - openai_api_key
    volumes:
      - ./build:/app/build
      # Mount NotePlan directory for seeding scripts
      - "/Users/omareid/Library/Containers/co.noteplan.NotePlan3/Data/Library/Application Support/co.noteplan.NotePlan3/:/noteplan:ro"
    depends_on:
      postgres:
        condition: service_healthy
      qdrant:
        condition: service_healthy
      llm-proxy:
        condition: service_healthy
    restart: "no"  # Only run once, don't restart
    profiles:
      - seeding  # Only start when explicitly requested

volumes:
  postgres_data:
  prometheus_data:
  qdrant_data:

secrets:
  openai_api_key:
    file: ./secrets/openai_api_key.txt
  admin_api_key:
    file: ./secrets/admin_api_key.txt
